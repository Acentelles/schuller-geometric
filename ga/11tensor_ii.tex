\subsection{Vector fields}

Now that we have defined the tangent bundle, we are ready to define vector fields.

\bd
Let $M$ be a smooth manifold, and let $TM$ be its tangent bundle. A \emph{vector field}\index{vector field} on $M$ is a smooth section of the tangent bundle, i.e.\ a smooth map $\sigma\cl M \to TM$ such that $\pi \circ \sigma = \id_M$.
\bse
\begin{tikzcd}
TM \ar[dd,shift left,"\pi"] \\
\\
M \ar[uu,shift left,"\sigma"]
\end{tikzcd}
\ese
\ed
We denote the set of all vector fields on $M$ by $\Gamma(TM)$\index{$\Gamma(TM)$}, i.e.\
\bse
\Gamma(TM) := \{\sigma \cl M \to TM \mid \sigma \text{ is smooth and }\pi\circ\sigma=\id_M\}.
\ese
This is, in fact, the standard notation for the set of all sections on a bundle. We can equip the set $\Gamma(TM)$ with the following operations. The first is our, by now familiar, pointwise addition:
\bi{rrCl}
\oplus \cl & \Gamma(TM) \times \Gamma(TM) & \to & \Gamma(TM)\\
& (\sigma,\tau) & \mapsto & \sigma \oplus \tau,
\ei
where
\bi{rrCl}
\sigma \oplus \tau \cl & M & \to & \Gamma(TM)\\
& p & \mapsto & (\sigma \oplus \tau)(p) := \sigma(p) + \tau(p).
\ei
Note that the $+$ on the right hand side above is the addition in $T_pM$. More interestingly, we also define the following multiplication operation:
\bi{rrCl}
\odot \cl & C^\infty(M) \times \Gamma(TM) & \to & \Gamma(TM)\\
& (f,\sigma) & \mapsto & f\odot\sigma,
\ei
where
\bi{rrCl}
f \odot \sigma \cl & M & \to & \Gamma(TM)\\
& p & \mapsto & (f\odot \sigma)(p) := f(p) \sigma(p).
\ei
Note that since $f\in C^\infty(M)$, we have $f(p)\in \R$ and hence the multiplication above is the scalar multiplication on $T_pM$.

If we consider the triple $(C^\infty(M),+,\bullet)$, where $\bullet$ is pointwise function multiplication as defined in the section on algebras and derivations, then the triple $(\Gamma(TM),\oplus,\odot)$ satisfies
\begin{itemize}
\item $(\Gamma(TM),\oplus)$ is an abelian group, with $0\in \Gamma(TM)$ being the section that maps each $p\in M$ to the zero tangent vector in $T_pM$;
\item $\Gamma(TM)\sm\{0\}$ satisfies
\ben[label=\roman*)]
\item $\forall \, f \in C^\infty(M) : \forall \, \sigma,\tau \in \Gamma(TM) : f\odot(\sigma\oplus \tau)=(f\odot \sigma)\oplus (f\odot \tau)$;
\item $\forall \, f,g \in C^\infty(M) : \forall \,  \sigma \in \Gamma(TM): (f+g)\odot \sigma= (f \odot \sigma) \oplus (g \odot \sigma)$;
\item $\forall \, f,g \in C^\infty(M) :  \sigma \in \Gamma(TM) : (f\bullet g)\odot \sigma= f \odot (g \odot \sigma)$;
\item $\forall \, \sigma \in \Gamma(TM)  : 1 \odot \sigma = \sigma$,
\een
where $1\in C^\infty(M)$ maps every $p\in M$ to $1\in \R$.
\end{itemize}

These are precisely the axioms for a vector space! The only obstacle to saying that $\Gamma(TM)$ is a vector space over $C^\infty(M)$ is that the triple $(C^\infty(M),+,\bullet)$ is \emph{not} an algebraic field, but only a ring. We could simply talk about ``vector spaces over rings'', but vector spaces over ring have wildly different properties than vector spaces over fields, so much so that they have their own name: \emph{modules}.

\br
Of course, we could have defined $\odot$ simply as pointwise \emph{global} scaling, using the reals $\R$ instead of the real functions $C^\infty(M)$.
The, since $(\R,+,\cdot)$ is an algebraic field, we would then have the obvious $\R$-vector space structure on $\Gamma(TM)$. However, a basis for this vector space is necessarily uncountably infinite, and hence it does not provide a very useful decomposition for our vector fields.

Instead, the operation $\odot$ that we have defined allows for \emph{local} scaling, i.e.\ we can scale a vector field by a different value at each point, and a much more useful decomposition of vector fields within the module structure.
\er


\subsection{Rings and modules over a ring}

Unlike mathematicians, most people who apply mathematics tend to consider rings and modules somewhat esoteric objects, but they are not esoteric at all. As we have seen, they arise naturally in the study of manifolds and their unusual properties, at least when compared to fields and vector spaces, are of direct geometric relevance and make us understand the subject better.

For your benefit, we first recall some basic facts about rings.

\bd
A \emph{ring}\index{ring} is a triple $(R,+,\cdot)$ where $R$ is a set and $+,\cdot\cl R\times R\to R$ are maps satisfying the following axioms
\begin{itemize}
\item $(R,+)$ is an abelian group:
\ben[label=\roman*)]
\item $\forall \, a,b,c \in R : (a+b)+c=a+(b+c)$;
\item $\exists \, 0 \in R : \forall \, a \in R : a+0=0+a=a$;
\item $\forall \, a \in R : \exists \, {-a} \in R : a+(-a)=(-a)+a=0$;
\item $\forall \, a,b \in R : a+b=b+a$;
\een
\item the operation $\cdot$ is associative and distributes over addition:
\ben[label=\roman*),start=5]
\item $\forall \, a,b,c \in R : (a\cdot b)\cdot c=a\cdot (b\cdot c)$;
\item $\forall \, a,b,c \in R : (a+ b)\cdot c=a\cdot c + b\cdot c$;
\item $\forall \, a,b,c \in R : a \cdot (b+c)=a\cdot b + a\cdot c$.
\een
\end{itemize}
Note that since $\cdot$ is not required to be commutative, axioms vi and vii are both necessary.
\ed

\bd 
A ring $(R,+,\cdot)$ is said to be
\begin{itemize}
\item \emph{commutative} if $\ \forall \, a,b\in R : a\cdot b = b \cdot a$;
\item \emph{unital} if $\ \exists\, 1\in R : \forall \, a\in R : 1\cdot a = a \cdot 1 = a$;
\item \emph{a division ring} if it is unital and $\ \forall\, a \in R : \exists \, a^{-1}\in R:a\cdot a^{-1}=a^{-1}\cdot a = 1$.
\end{itemize}
\ed

Division rings are also called \emph{skew rings}. In a unital ring, an element for which there exists a multiplicative inverse is said to be a \emph{unit}. The set of units of a ring $R$ is denoted $R^*$ (not to be confused with the vector space dual) and forms a group under multiplication. Then $R$ is a division ring iff $R^*=R\sm\{0\}$.

\be
The sets $\Z$, $\Q$, $\R$, and $\C$ are all rings under the usual operations. They are also all fields, except $\Z$.
\ee

\be
Let $M$ be a smooth manifold. Then
\begin{itemize}
\item $(C^\infty(M),+,\cdot)$, where $\cdot$ is scalar multiplication (by a real number) is an $\R$-vector space. It is not a ring since $\cdot$ is not a map $C^\infty(M)\times C^\infty(M) \to C^\infty(M)$.
\item $(C^\infty(M),+,\bullet)$, where $\bullet$ is pointwise multiplication of maps, is a commutative, unital ring, but not a division ring and hence, not a field.
\end{itemize}
In general, if $(A,+,\cdot,\bullet)$ is an algebra, then $(A,+,\bullet)$ is a ring.
\ee

\bd
Let $(R,+,\cdot)$ be a unital ring. A triple $(M,\oplus,\odot)$ is called an \emph{$R$-module}\index{module} if the maps
\bi{rrCl}
\oplus \cl & M \times M & \to & M\\
\odot \cl & R \times M & \to & M
\ei
satisfy the vector space axioms, i.e.\ $(M,\oplus)$ is an abelian group and for all $r,s\in R$ and all $m,n\in M$, we have
\ben[label=\roman*)]
\item $r \odot (m\oplus n) = (r \odot m) \oplus (r \odot n)$;
\item $(r+s)\odot m = (r\odot m)\oplus (s\odot m)$;
\item $(r\cdot s)\odot m = r \odot (s\odot m)$;
\item $1 \odot m = m$.
\een
\ed

Most definitions we had for vector spaces carry over unaltered to modules, including that of a basis, i.e.\ a linearly independent spanning set.

\br
Even though we will not need this, we note as an aside that what we have defined above is a \emph{left} $R$-module, since multiplication has only been defined (and hence only makes sense) on the left. The definition of a \emph{right} $R$-module is completely analogous. Moreover, if $R$ and $S$ are two unital rings, then we can define $M$ to be an \emph{$R$-$S$-bimodule} if it is a left $R$-module and a right $S$-module. The bimodule structure is precisely what is needed to generalise the notion of derivation that we have met before.
\er

\be
Any ring $R$ is trivially a module over itself.
\ee

\be
The triple $(\Gamma(TM),\oplus,\odot)$ is a $C^\infty(M)$-module.
\ee

In the following, we will usually denote $\oplus$ by $+$ and suppress the $\odot$, as we did with vector spaces.

\subsection{Bases for modules}

The key fact that sets modules apart from vector spaces is that, unlike a vector space, an $R$-module need not have a basis, unless $R$ is a division ring. 

\begin{theorem}
\label{thm:everybasis}
If $D$ is a division ring, then any $D$-module $V$ admits a basis.
\end{theorem}

\bc
Every vector space has a basis, since any field is also a division ring.
\ec

Before we delve into the proof, let us consider some geometric examples.

\be
\ben[label=\alph*)]
\item Let $M = \R^2$ and consider $v\in \Gamma(T\R^2)$. It is a fact from standard vector analysis that any such $v$ can be written uniquely as
\bse
v=v^1e_1+v^2e_2
\ese
for some $v^1,v^2\in C^\infty(\R^2)$ and $e_1,e_2\in \Gamma(T\R^2)$. Hence, even though $\Gamma(T\R^2)$ is a $C^\infty(\R^2)$-module and $C^\infty(\R^2)$ is \emph{not} a division ring, it still has a basis. Note that the coefficients in the linear expansion of $v$ are functions.

This example shows that the converse to the above theorem is not true: if $D$ is not a division ring, then a $D$-module may or may not have a basis.

\item Let $M=S^2$. A famous result in algebraic topology, known as the \emph{hairy ball theorem}\index{hairy ball theorem}, states that there is no non-vanishing smooth tangent vector field on even-dimensional $n$-spheres. Hence, we can multiply any smooth vector field $v\in\Gamma(TS^2)$ by a function $f\in C^\infty(S^2)$ which is zero everywhere except where $v$ is, obtaining $fv=0$ despite $f\neq 0$ and $v\neq 0$. Therefore, there is no set of linearly independent vector fields on $S^2$, much less a basis.
\een
\ee

The proof of the theorem requires the axiom of choice, in the equivalent form known as Zorn's lemma.

\bl[Zorn]\index{Zorn's lemma}
A partially ordered set $P$ whose every totally ordered subset $T$ has an upper bound in $P$ contains a maximal element.
\el

Of course, we now need to define the new terms introduced by the lemma. 

\bd
A \emph{partially ordered set} (\emph{poset} for short) is a pair $(P,\leq)$ where $P$ is a set and~$\leq$ is a \emph{partial order} on $P$, i.e.\ a relation on $P$ satisfying
\ben[label=\roman*)]
\item \emph{reflexivity:} $\ \forall \, a \in P: a\leq a$;
\item \emph{anti-symmetry:} $\ \forall \, a,b\in P : ( a\leq b \land b\leq a) \imp a=b$;
\item \emph{transitivity:} $\ \forall \, a,b,c\in P:(a\leq b \land b\leq c)\imp a\leq c$.
\een
\ed
In a partially ordered set, while every element is related to itself by reflexivity, two distinct elements need not be related.
\bd
A \emph{totally ordered set} is a pair $(P,\leq)$ where $P$ is a set and $\leq$ is a \emph{total order} on $P$, i.e.\ a relation on $P$ satisfying
\ben[label=\alph*)]
\item \emph{anti-symmetry:} $\ \forall \, a,b\in P : ( a\leq b \land b\leq a) \imp a=b$;
\item \emph{transitivity:} $\ \forall \, a,b,c\in P:(a\leq b \land b\leq c)\imp a\leq c$;
\item \emph{totality:} $\ \forall \, a,b \in P: a\leq b\lor b\leq a$.
\een
\ed
Note that a total order is a special case of a partial order since, by letting $a=b$ in the totality condition, we obtain reflexivity. In a totally ordered set, every pair of elements is related. 
\bd
Let $(P,\leq)$ be a partially ordered set and let $T\se P$. An element $u\in P$ is said to be an \emph{upper bound} for $T$ if
\bse
\forall \, t\in T :\ t\leq u.
\ese
\ed
Every single-element subset of a partially ordered set has at least one upper bound by reflexivity. However, in general, a subset may not have any upper bound. For example, if the subset contains an element which is not related to any other element.
\bd
Let $(P,\leq)$ be a partially ordered set. A \emph{maximal element} of $P$ is an element $m\in P$ such that
\bse
\nexists \, a \in P :\ m \leq a
\ese
or, alternatively,
\bse
\forall \, a\in P :\ (m\leq a) \imp (m=a).
\ese
Note that this is \emph{not} equivalent to 
\bse
\forall \, a\in P :\ a\leq m
\ese
unless $(P,\leq)$ is a totally ordered set.
\ed

We are now ready to prove the theorem.

\bq[Proof of \Cref{thm:everybasis}] We will tackle this one step at a time.
\ben[label=\alph*)]

\item Let $S\se V$ be a generating set of $V$, i.e.\
\bse
\forall \, v \in V : \exists \, e_1,\ldots,e_N\in S : \exists \,d^1,\ldots,d^N\in D : \ v=d^ae_a. 
\ese
A generating set always exists, as one may take $S=V$.

\item Define a partially ordered set $(P,\leq)$ by
\bse
P:=\{U\in \mathcal{P}(S)\mid U \text{ is linearly independent}\}
\ese
and $\leq\medspace :=\medspace \se$, we partial order by set-theoretic inclusion.
\item Let $T\se P$ be any totally ordered subset of $P$. Then $\bigcup T$ is an upper bound for $T$, and it is linearly independent (by the total ordering assumption). Hence $\bigcup T \in P$.

By Zorn's lemma, $P$ has a maximal element. Le $\mathcal{B}\in P$ be any such element. BY construction, $\mathcal{B}$ is a maximal (with respect to inclusion) linearly independent subset of the generating set $S$.

\item We now claim that $S=\lspan_D(\mathcal{B})$. Indeed, let $v\in S\sm\mathcal{B}$. Then $\mathcal{B}\cap \{v\}\in \mathcal{P}(S)$. Since $\mathcal{B}$ is maximal, the set $\mathcal{B}\cap \{v\}$ is \emph{not} linearly independent. Hence
\bse
\exists\, e_1,\ldots,e_N\in\mathcal{B}:\exists\, d,d^1,\ldots,d^N\in D : \ d^ae_a+dv=0,
\ese
where the coefficients $d,d^1,\ldots,d^N$ are not all zero. In particular, $d\neq 0$, for if it was, it would immediately follow that $d^ae_a=0$ for some $d^1,\ldots,d^N$, not all zero, contradicting the linear independence of $\mathcal{B}$.

Since $D$ is a division ring and $d\neq 0$, there exists a multiplicative inverse for $d$. Then we can multiply both sides of the above equation by $d^{-1}\in D$ to obtain
\bse
v= (d^{-1}\cdot d^a) \, e_a.
\ese
Hence $S=\lspan_D(\mathcal{B})$.
\item We therefore have
\bse
V=\lspan_D(S)=\lspan_D(\mathcal{B})
\ese
and thus $\mathcal{B}$ is a basis of $V$. \qedhere
\een
\eq

We stress again that if $D$ is not a division ring, then a $D$-module may, but need not, have a basis.

\subsection{Module constructions and applications}

As for vector spaces, we can perform the usual constructions with modules as well.

\bd
The \emph{direct sum} of two $R$-modules $M$ and $N$ is the $R$-module $M\oplus N$, which has $M\times N$ as its underlying set and operations (inherited from $M$ and $N$) defined componentwise. 
\ed

Note that while we have been using $\oplus$ to temporarily distinguish two ``plus-like'' operations in different spaces, the symbol $\oplus$ is the standard notation for the direct sum.

\bd
An $R$-module $M$ is said to be
\begin{itemize}
\item \emph{finitely generated} if it has a finite generating set;
\item \emph{free} is it has a basis;
\item \emph{projective} if it is a direct summand of a free $R$-module $F$, i.e.\
\bse
M \oplus Q = F
\ese
for some $R$-module $Q$.
\end{itemize}
\ed

\be
As we have seen, $\Gamma(T\R^2)$ is free while $\Gamma(TS^2)$ is not. 
\ee
\be
Clearly, every free module is also projective.
\ee

\bd
Let $M$ and $N$ be two (left) $R$-modules. A map $f\cl M \to N$ is said to be an\emph{$R$-linear map}, or an \emph{$R$-module homomorphism}, if
\bse
\forall \, r\in R : \forall \, m_1,m_2\in M : \ f(rm_1 + m_2)=rf(m_1)+f(m_2),
\ese
where it should be clear which operations are in $M$ and which in $N$.

A bijective module homomorphism is said to be a \emph{module isomorphism}\index{isomorphism!of modules}, and we write $M\cong_{\mathrm{mod}}N$ if there exists a module isomorphism between them.
\ed
If $M$ and $N$ are right $R$-modules, then the linearity condition is written as
\bse
\forall \, r\in R : \forall \, m_1,m_2\in M : \ f(m_1r + m_2)=f(m_1)r+f(m_2).
\ese

\bp
If a finitely generated module $R$-module $F$ is free, and $d\in \N$ is the cardinality of a finite basis, then
\bse
F\cong_\mathrm{mod} = \underbrace{R\oplus\cdots\oplus R}_{d \text{ copies}} =: R^d.
\ese
\ep
One can show that if $R^d\cong_\mathrm{mod} R^{d'}$, then $d=d'$ and hence, the concept of dimension is well-defined for finitely generated, free modules.

\begin{theorem}[Serre, Swan, et al.]
Let $E$ be a vector fibre bundle over a smooth manifold $M$. Then, the set $\Gamma(E)$ of all smooth section of $E$ over $M$ is a finitely generated, projective $C^\infty(M)$-module.
\end{theorem}

A vector fibre bundle is a fibre bundle in which every fibre is a vector space. An example is the tangent bundle to a manifold.

\br
An immediate consequence of the theorem is that, for any vector fibre bundle $E$ over $M$, there exists a $C^\infty(M)$-module $Q$ such that the direct sum $\Gamma(E)\oplus Q$ is free. If $Q$ can be chosen to be the trivial module $\{0\}$, then $\Gamma(E)$ is itself free, as it is the case with $\Gamma(T\R^2)$. In a sense, the module $Q$ quantifies the failure of $\Gamma(E)$ to have a basis.
\er

\begin{theorem}
Let $P,Q$ be finitely generated (projective) modules over a commutative ring $R$. Then
\bse
\Hom_R(P,Q) := \{\phi\cl P \xrightarrow{\sim} Q \mid \phi \text{ \normalfont is $R$-linear}\}
\ese
is again a finitely generated (projective) $R$-module, with operations defined pointwise.
\end{theorem}

The proof is exactly the same as with vector spaces.

\be
In particular, we can use this to define the dual of a module. For instance
\bse
\Hom_{C^\infty(M)}(\Gamma(TM),C^\infty(M)) =: \Gamma(TM)^*.
\ese
One can show that $\Gamma(TM)^*$ coincides with the smooth sections over the cotangent bundle $\Gamma(T^*M)$, i.e.\ the covector fields.
\ee

We are now fully prepared to give the following standard textbook definition.

\bd
Let $M$ be a smooth manifold. An \emph{$(r,s)$ smooth tensor field}\index{tensor field} $\tau$ on $M$ is a $C^\infty(M)$-multilinear map
\bse
\tau\cl \underbrace{\Gamma(T^*M)\times \cdots \times \Gamma(T^*M)}_{r \text{ copies}} \times \underbrace{\Gamma(TM)\times \cdots \times \Gamma(TM)}_{s \text{ copies}} \to C^\infty(M).
\ese
We denote by $T^r_sM$ the $C^\infty(M)$-module of all $(r,s)$ smooth tensor fields on $M$, with module operations defined pointwise.
\ed
We can also define the tensor product of tensor fields
\bi{rrCl}
\otimes \cl & T^p_qM \times T^r_sM & \to & T^{p+r}_{q+s}M\\
&(\tau,\sigma) & \mapsto & \tau \otimes \sigma
\ei
analogously to what we had with tensors on a vector space, i.e.\
\bi{rl}
(\tau\otimes \sigma)(\omega_1,\ldots,\omega_p,\omega_{p+1},\ldots,\omega_{p+r},X_1,&\ldots,X_q,X_{q+1},\ldots,X_{q+s})\\
:=\tau(\omega_1,\ldots,\omega_p,X_1,&\ldots,X_q)\,\sigma(\omega_{p+1},\ldots,\omega_{p+r},X_{q+1},\ldots,X_{q+s}),
\ei
with $\omega_i\in \Gamma(T^*M)$ and $X_i\in \Gamma(TM)$.















